# Import , Netoyage et Classification des tweets 
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/aminasridi/Import-Netoyage-et-Classification-des-tweets-/main) 
<br>
![téléchargement](https://user-images.githubusercontent.com/24653616/102296651-1a873680-3f4e-11eb-9c8a-6d5e629a1812.png)  

## Objectifs :
*   Maitriser l’API de twitter pour l’extraction des tweets
*   Appliquer les principes de nettoyage des données
*   Maitriser la partie NLP avec NLTK en Python
*   Classer les tweets

Ce travail contient 4 parties :
## 1.   Partie 1 :Extraction des tweets 
Le code source de cette étape doit étre executer si seulement vous aimerai traiter le code from Scratch
## 2.   Partie 2 : Prétraitement des tweets
Dans cette étape vous allez utiliser les fichiers : <br>
[extractionNews1Twitter.csv](https://github.com/aminasridi/Import-Netoyage-et-Classification-des-tweets-/blob/main/extractionNews1Twitter.csv)   
[extractionNews2Twitter.csv](https://github.com/aminasridi/Import-Netoyage-et-Classification-des-tweets-/blob/main/extractionNews2Twitter.csv)<br> 
[extractionNews3Twitter.csv](https://github.com/aminasridi/Import-Netoyage-et-Classification-des-tweets-/blob/main/extractionNews3Twitter.csv)<br> 
[corpus_clean.csv](https://github.com/aminasridi/Import-Netoyage-et-Classification-des-tweets-/blob/main/corpus_clean.csv)<br> 

l’objectif est d’éliminer le texte inutile des tweets tels que les #, les noms des utilisateurs, les url, …
## 3.   Partie 3 :Traitement des tweets : NLP (Natural LanguageProcessing)
 Cette étape procéde à l’analyse du tweet en respectant les différentes étapes du NLP:
                *   Segmentation 
                *   Tokenization
                *   Lemmatisation
                *   Sremming
## 4.   Partie 4 :Classification des tweets
1.    Transforme le texte en une matrice
2.    KMeans <br>


 



