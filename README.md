# Import , Netoyage et Classification des tweets 
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/aminasridi/Import-Netoyage-et-Classification-des-tweets-/main)
![téléchargement](https://user-images.githubusercontent.com/24653616/102296651-1a873680-3f4e-11eb-9c8a-6d5e629a1812.png)  
## Objectifs :
*   Maitriser l’API de twitter pour l’extraction des tweets
*   Appliquer les principes de nettoyage des données
*   Maitriser la partie NLP avec NLTK en Python
*   Classer les tweets

Ce travail contient 4 parties :
## 1.   Partie 1 :Extraction des tweets 
Le code source de cette étape doit étre executer si seulement vous aimerai traiter le code from Scratch
## 2.   Partie 2 : Prétraitement des tweets
Dans cette étape vous allez utiliser les fichiers extractionNews1Twitter.csv  extractionNews2Twitter.csv extractionNews3Twitter.csv corpus_clean.csv
l’objectif est d’éliminer le texte inutile des tweets tels que les #, les noms des utilisateurs, les url, …
## 3.   Partie 3 :Traitement des tweets : NLP (Natural LanguageProcessing)
 Cette étape procéde à l’analyse du tweet en respectant les différentes étapes du NLP:
                *   Segmentation 
                *   Tokenization
                *   Lemmatisation
                *   Sremming
## 4.   Partie 4 :Classification des tweets
1.    Transforme le texte en une matrice
2.    KMeans



